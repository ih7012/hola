{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyuOCYM92LJb"
      },
      "source": [
        "# Getting Started with Fine-Tuning Moshi 7B\n",
        "\n",
        "This notebook shows you a simple example of how to LoRA finetune Moshi 7B. You can run this notebook in Google Colab using a A100 GPU.\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github//kyutai-labs/moshi-finetune/blob/main/tutorials/moshi_finetune.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "Check out `moshi-finetune` Github repo to learn more: https://github.com/kyutai-labs/moshi-finetune/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxr8mv-17GfB"
      },
      "source": [
        "## Installation\n",
        "\n",
        "Clone the `moshi-finetune` repo:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIj3IlIeVDIb",
        "outputId": "979e3769-d291-4177-c81e-7b72c79cd3ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'moshi-finetune'...\n",
            "remote: Enumerating objects: 245, done.\u001b[K\n",
            "remote: Counting objects: 100% (55/55), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 245 (delta 36), reused 35 (delta 29), pack-reused 190 (from 1)\u001b[K\n",
            "Receiving objects: 100% (245/245), 638.97 KiB | 14.52 MiB/s, done.\n",
            "Resolving deltas: 100% (135/135), done.\n"
          ]
        }
      ],
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/kyutai-labs/moshi-finetune.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQPd_pGT7WiY"
      },
      "source": [
        "Install all required dependencies:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuTOGipl7BS7",
        "outputId": "cf4492d1-84c6-4b09-8b25-1eb97441cd20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m116.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m96.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m137.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
          ]
        }
      ],
      "source": [
        "%pip install -e /content/moshi-finetune"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ams-19wF8zgY"
      },
      "source": [
        "## Prepare dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0hDgFmn0IW7"
      },
      "outputs": [],
      "source": [
        "# from pathlib import Path\n",
        "\n",
        "# from huggingface_hub import snapshot_download\n",
        "\n",
        "# Path(\"/content/data/daily-talk-contiguous\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# # Download the dataset\n",
        "# local_dir = snapshot_download(\n",
        "#     \"kyutai/DailyTalkContiguous\",\n",
        "#     repo_type=\"dataset\",\n",
        "#     local_dir=\"/content/data/daily-talk-contiguous\",\n",
        "# )\n",
        "\n",
        "# Delete any old directory.\n",
        "!rm -rf sample_data\n",
        "!rm -rf dailytalk_dataset\n",
        "\n",
        "# Create new directories.\n",
        "!mkdir dailytalk_dataset\n",
        "!mkdir dailytalk_dataset/data_stereo\n",
        "\n",
        "# Download jsonl file\n",
        "!wget -q https://huggingface.co/datasets/kyutai/DailyTalkContiguous/resolve/main/dailytalk.jsonl -O dailytalk_dataset/dailytalk.jsonl\n",
        "\n",
        "# Download file 1-100 for now.\n",
        "base_url = \"https://huggingface.co/datasets/kyutai/DailyTalkContiguous/blob/main/data_stereo/\"\n",
        "from tqdm.auto import tqdm\n",
        "for i in tqdm(range(1, 10)):\n",
        "    !wget -q {base_url}{i}.wav -O dailytalk_dataset/data_stereo/{i}.wav\n",
        "    !wget -q {base_url}{i}.json -O dailytalk_dataset/data_stereo/{i}.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hia7n0T1_mHZ"
      },
      "source": [
        "## Start training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtcLerooWFeB"
      },
      "outputs": [],
      "source": [
        "# these info is needed for training\n",
        "import os\n",
        "\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dxTlIQMaJGv"
      },
      "outputs": [],
      "source": [
        "# define training configuration\n",
        "# for your own use cases, you might want to change the data paths, model path, run_dir, and other hyperparameters\n",
        "import yaml\n",
        "\n",
        "config = \"\"\"\n",
        "# data\n",
        "data:\n",
        "  train_data: '/content/data/daily-talk-contiguous/dailytalk.jsonl' # Fill\n",
        "  eval_data: '' # Optionally Fill\n",
        "  shuffle: true\n",
        "\n",
        "# model\n",
        "moshi_paths:\n",
        "  hf_repo_id: \"kyutai/moshiko-pytorch-bf16\"\n",
        "\n",
        "\n",
        "full_finetuning: false # Activate lora.enable if partial finetuning\n",
        "lora:\n",
        "  enable: true\n",
        "  rank: 128\n",
        "  scaling: 2.\n",
        "  ft_embed: false\n",
        "\n",
        "# training hyperparameters\n",
        "first_codebook_weight_multiplier: 100.\n",
        "text_padding_weight: .5\n",
        "\n",
        "\n",
        "# tokens per training steps = batch_size x num_GPUs x duration_sec\n",
        "# we recommend a sequence duration of 300 seconds\n",
        "# If you run into memory error, you can try reduce the sequence length\n",
        "duration_sec: 100\n",
        "batch_size: 1\n",
        "max_steps: 300\n",
        "\n",
        "gradient_checkpointing: true # Activate checkpointing of layers\n",
        "\n",
        "# optim\n",
        "optim:\n",
        "  lr: 2.e-6\n",
        "  weight_decay: 0.1\n",
        "  pct_start: 0.05\n",
        "\n",
        "# other\n",
        "seed: 0\n",
        "log_freq: 10\n",
        "eval_freq: 1\n",
        "do_eval: False\n",
        "ckpt_freq: 10\n",
        "\n",
        "save_adapters: True\n",
        "\n",
        "run_dir: \"/content/test\"  # Fill\n",
        "\"\"\"\n",
        "\n",
        "# save the same file locally into the example.yaml file\n",
        "with open(\"/content/example.yaml\", \"w\") as file:\n",
        "    yaml.dump(yaml.safe_load(config), file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ErD1ktQUMyPZ"
      },
      "outputs": [],
      "source": [
        "# make sure the run_dir has not been created before\n",
        "# only run this when you ran torchrun previously and created the /content/test_ultra file\n",
        "# ! rm -r /content/test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4wFgmwIUTtg"
      },
      "outputs": [],
      "source": [
        "# start training\n",
        "\n",
        "!cd /content/moshi-finetune && torchrun --nproc-per-node 1 -m train /content/example.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruJ29JFn98zE"
      },
      "source": [
        "## Inference\n",
        "\n",
        "Once the model has been trained, inference can be run on the colab GPU too, and gradio can be used to tunnel the audio data from a local client to the notebook.\n",
        "\n",
        "More details on how to set this up can be found in the [moshi readme](https://github.com/kyutai-labs/moshi?tab=readme-ov-file#python-pytorch).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEPBTcx40IW_"
      },
      "outputs": [],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-xLs2Ot9-il"
      },
      "outputs": [],
      "source": [
        "!python -m moshi.server --gradio-tunnel --lora-weight=/content/test/checkpoints/checkpoint_000300/consolidated/lora.safetensors --config-path=/content/test/checkpoints/checkpoint_000300/consolidated/config.json"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}